# -*- coding: utf-8 -*-
"""kryptologia.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1adM-TQRCJX0FRr3vDUu6N9hGDcQ-GtTv
"""

import cv2
print("OpenCV-Python Version {}".format(cv2.__version__))

"""
Wczytanie bibliotek
"""
import numpy as np
import cv2
import cv2
import os
import sys
import math
import random
import _pickle as pickle
import copy
import gzip
import inspect
import itertools


from matplotlib import pyplot as plt

"""
Porównuje dwa obrazy, których ścieżki są podane jako argumenty filepath1 i filepath2.
Najpierw wczytuje obszary zainteresowania (ROIs) z obu obrazów za pomocą funkcji load_rois_from_image().
Następnie wywołuje funkcję getall_matches() do porównania tych obszarów z określonymi parametrami i opcją wyświetlania wyników.

"""
def compare_images(filepath1, filepath2):
    print ("Analysing " + filepath1)
    rois_1 = load_rois_from_image(filepath1)

    print ("Analysing " + filepath2)
    rois_2 = load_rois_from_image(filepath2)

    numberOfMatches = getall_matches(rois_1, rois_2, 0.8, 10, 0.15, show=True)

    return numberOfMatches

# """
# Porównuje dwa pliki binarne zawierające dane obrazów, których ścieżki są podane jako argumenty bin_path1 i
# bin_path2. Podobnie jak w przypadku compare_images(), wczytuje obszary zainteresowania (ROIs) z obu plików za pomocą funkcji
# load_rois_from_bin(). Następnie wywołuje funkcję getall_matches() do porównania tych obszarów z określonymi parametrami i opcją wyświetlania wyników.
# """
# def compare_binfiles(bin_path1, bin_path2):
#     print ("Analysing " + bin_path1)
#     rois_1 = load_rois_from_bin(bin_path1)

#     print( "Analysing " + bin_path2)
#     rois_2 = load_rois_from_bin(bin_path2)

#     getall_matches(rois_1, rois_2, 0.88, 10, 0.07, show=True)

"""
 Wczytuje obraz z podanej ścieżki filepath i przetwarza go w celu uzyskania obszarów zainteresowania (ROIs).
 Najpierw wczytuje obraz za pomocą funkcji load_image(). Następnie znajduje granice tęczówki za pomocą funkcji get_iris_boundaries().
 Po znalezieniu granic, wykonuje kilka operacji przetwarzania obrazu, takich jak wyrównywanie histogramu, aby uzyskać ROI.
  Następnie znajduje ROIs wewnątrz granic tęczówki za pomocą funkcji get_rois(). Na koniec korzysta z
algorytmu SIFT (Skalable Invariant Feature Transform) do wyszukiwania punktów charakterystycznych i oblicza deskryptory dla tych punktów.
Deskryptory są numerycznymi reprezentacjami cech obrazu, które są używane do opisania
 """
def load_rois_from_image(filepath):
    img = load_image(filepath, show=False)

    print ("Getting iris boundaries..")
    pupil_circle, ext_iris_circle = get_iris_boundaries(img, show=True)
    if not pupil_circle or not ext_iris_circle:
        print ("Error finding iris boundaries!")
        return

    print ("Equalizing histogram ..")
    roi = get_equalized_iris(img, ext_iris_circle, pupil_circle, show=True)

    print ("Getting roi iris images ...")
    rois = get_rois(roi, pupil_circle, ext_iris_circle, show=True)

    print ("Searching for keypoints ... \n")
    sift = cv2.SIFT_create()
    load_keypoints(sift, rois, show=True)
    load_descriptors(sift, rois)

    return rois

"""
Wczytuje obraz z podanej ścieżki filepath za pomocą biblioteki OpenCV (cv2).
Jeśli argument show jest ustawiony na True, wyświetla obraz w oknie.
"""
def load_image(filepath, show=True):
    img = cv2.imread(filepath, 0)
    if show:
        window_name = filepath
        cv2.imshow(window_name, img)
        ch = cv2.waitKey(0)
        cv2.destroyAllWindows()
    return img

"""
Znajduje granice tęczówki na podstawie wczytanego obrazu. Wykorzystuje algorytmy przetwarzania obrazu,
takie jak progowanie, wykrywanie krawędzi i wykrywanie okręgów. Zwraca współrzędne okręgu
źrenicy (pupil_circle) i okręgu zewnętrznego tęczówki (ext_iris_circle).
"""
def get_iris_boundaries(img, show=False):
    # Finding iris inner boundary
    pupil_circle = find_pupil(img)

    if not pupil_circle:
        print ('ERROR: Pupil circle not found!')
        return None, None

    # Finding iris outer boundary
    radius_range = int(math.ceil(pupil_circle[2]*1.5))
    multiplier = 0.25
    center_range = int(math.ceil(pupil_circle[2]*multiplier))
    ext_iris_circle = find_ext_iris(
                        img, pupil_circle, center_range, radius_range)

    while(not ext_iris_circle and multiplier <= 0.7):
        multiplier += 0.05
        print ('Searching exterior iris circle with multiplier ' + \
              str(multiplier))
        center_range = int(math.ceil(pupil_circle[2]*multiplier))
        ext_iris_circle = find_ext_iris(img, pupil_circle,
                                        center_range, radius_range)
    if not ext_iris_circle:
        print ('ERROR: Exterior iris circle not found!')
        return None, None

    if show:
        cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)
        draw_circles(cimg, pupil_circle, ext_iris_circle,
                     center_range, radius_range)
        window_name = 'iris boundaries'
        cv2.imshow(window_name, cimg)
        ch = cv2.waitKey(0)
        cv2.destroyAllWindows()

    return pupil_circle, ext_iris_circle

"""
Znajduje okrąg reprezentujący źrenicę na podstawie wczytanego obrazu.
 Wykorzystuje algorytmy przetwarzania obrazu, takie jak progowanie, wygładzanie,
 wykrywanie konturów i wykrywanie okręgów. Zwraca współrzędne i promień okręgu źrenicy.
"""
def find_pupil(img):
    def get_edges(image):
        edges = cv2.Canny(image,20,100)
        kernel = np.ones((3,3),np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=2)
        ksize = 2 * random.randrange(5,11) + 1
        edges = cv2.GaussianBlur(edges,(ksize,ksize),0)
        return edges

    param1 = 200 # 200
    param2 = 120 # 150
    pupil_circles = []
    while(param2 > 35 and len(pupil_circles) < 100):
        for mdn,thrs in [(m,t)
                         for m in [3,5,7]
                         for t in [20,25,30,35,40,45,50,55,60]]:
            # Median Blur
            median = cv2.medianBlur(img, 2*mdn+1)

            # Threshold
            ret, thres = cv2.threshold(
                            median, thrs, 255,
                            cv2.THRESH_BINARY_INV)

            # Fill Contours
            """
            1) Contours is a Python list of all the contours in the image. Each individual contour is a Numpy array of (x,y) coordinates of boundary points of the object.

2) Hierarchy is the parent-child relationship in contours. It is represented as an array of four values : [Next contour, previous contour, First child contour, Parent contour]
            """
            contours, hierarchy = \
                    cv2.findContours(thres.copy(),
                                     cv2.RETR_EXTERNAL,
                                     cv2.CHAIN_APPROX_NONE)
            draw_con = cv2.drawContours(thres, contours, -1, (255), -1)

            # Canny algortm
            edges = get_edges(thres)

            # HoughCircles
            circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 1,
                                       param1=param1, param2=param2)
            if circles is not None:
                circles = np.round(circles[0, :]).astype("int")
                for c in circles:
                    pupil_circles.append(c)

        param2 = param2 -1

    cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)

    return get_mean_circle(pupil_circles)

"""
Oblicza średnią wartość współrzędnych x, y i promienia
dla danej listy okręgów. Opcjonalnie rysuje ten średni okrąg na obrazie.
"""
def get_mean_circle(circles, draw=None):
    if not circles:
        return
    mean_0 = int(np.mean([c[0] for c in circles]))
    mean_1 = int(np.mean([c[1] for c in circles]))
    mean_2 = int(np.mean([c[2] for c in circles]))

    if draw is not None:
        draw = draw.copy()
        # draw the outer circle
        cv2.circle(draw,(mean_0,mean_1),mean_2,(0,255,0),1)
        # draw the center of the circle
        cv2.circle(draw,(mean_0,mean_1),2,(0,255,0),2)
        window_name = 'mean_circle'
        cv2.imshow(window_name, draw)
        ch = cv2.waitKey(0)
        cv2.destroyAllWindows()

    return mean_0, mean_1, mean_2

"""
Znajduje okrąg zewnętrzny tęczówki na podstawie wczytanego obrazu i okręgu źrenicy.
Wykorzystuje podobne metody jak funkcja find_pupil(). Zwraca współrzędne i promień okręgu zewnętrznego tęczówki.
"""
def find_ext_iris(img, pupil_circle, center_range, radius_range):
    """
    Definiuje  funkcję `get_edges`, która pobiera obraz i wartość progową
    (`thrs2`). Funkcja wykonuje wykrywanie krawędzi na obrazie przy użyciu algorytmu wykrywania
    krawędzi Canny'ego. Stosuje dylatację, rozmycie gaussowskie i zwraca wynikowe krawędzie.
    """
    def get_edges(image, thrs2):
        thrs1 = 0 # 0
        edges = cv2.Canny(image, thrs1, thrs2, apertureSize=5)
        kernel = np.ones((3,3),np.uint8)
        edges = cv2.dilate(edges, kernel, iterations=1)
        ksize = 2 * random.randrange(5,11) + 1
        edges = cv2.GaussianBlur(edges,(ksize,ksize),0)
        return edges
    """
    Definiuje funkcję `get_circles`, która przyjmuje parametry wykrywania okręgu Hougha, rozmycia mediany i
    wykrywania krawędzi. Ta funkcja wykonuje następujące kroki dla każdej kombinacji parametrów mediany i krawędzi:
    - Stosuje filtr medianowy do rozmycia obrazu wejściowego.
    - Uzyskuje krawędzie za pomocą funkcji `get_edges`.
    - Wykrywa okręgi algorytmem Hougha (`cv2.HoughCircles`).
    - W przypadku wykrycia okręgów konwertuje współrzędne i promień na liczby całkowite i sprawdza, czy środek okręgu
    mieści się w podanym zakresie, a promień jest większy niż określony zakres. Jeśli warunki są spełnione,
    okrąg jest dodawany do listy `crt_circles`.
    - Zwraca listę `crt_circles` zawierającą wykryte okręgi .
    """
    def get_circles(hough_param, median_params, edge_params):
        crt_circles = []
        for mdn,thrs2 in [(m,t)
                          for m in median_params
                          for t in edge_params]:
            # rozmycie medianowe
            median = cv2.medianBlur(img, 2*mdn+1)

            # algorytm Canny
            edges = get_edges(median, thrs2)

            # HoughCircles
            circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, 1, 1,
                                       param1=200, param2=hough_param)
            if circles is not None:
                circles = np.round(circles[0, :]).astype("int")
                for (c_col, c_row, r) in circles:
                    if point_in_circle(
                            int(pupil_circle[0]), int(pupil_circle[1]),
                            center_range, c_col, c_row) and \
                       r > radius_range:
                        crt_circles.append((c_col, c_row, r))
        return crt_circles

    """Pętla, która trwa do momentu, gdy `param2` stanie się mniejszy lub równy 40 lub liczba okręgów w
    `total_circles` osiągnie 50. Wewnątrz pętli:
    - Wywołuje funkcję `get_circles` z daną wartością `param2` i określonymi parametrami mediany i krawędzi.
    - Jeśli kręgi zostaną wykryte (`crt_circles` nie jest puste), kręgi są dodawane do listy `total_circles`.
    - Wartość `param2` jest zmniejszana o 1 w każdej iteracji."""
    param2 = 120 # 150
    total_circles = []
    while(param2 > 40 and len(total_circles) < 50):
        crt_circles = get_circles(
                        param2, [8,10,12,14,16,18,20], [430,480,530])
        if crt_circles:
            total_circles += crt_circles
        param2 = param2 -1
    """
    Jeśli `total_circles` jest nadal puste, oznacza to, że pierwsza próba nie dała
    żadnych kółek. Wchodzi w drugą pętlę oz tymi samymi elementami jak poprzednia, ale z
    innymi parametrami mediany i krawędzi . Celem jest ponowna próba znalezienia
    okręgów przy użyciu różnych parametrów.
    """
    if not total_circles:
        print ("Running plan B on finding ext iris circle")
        param2 = 120
        while(param2 > 40 and len(total_circles) < 50):
            crt_circles = get_circles(
                            param2, [3,5,7,21,23,25], [430,480,530])
            if crt_circles:
                total_circles += crt_circles
            param2 = param2 -1
    """Jeśli `total_circles` po drugiej próbie nadal jest puste, funkcja zwraca `Brak`."""
    if not total_circles:
        return
    """
    Jeśli zostaną znalezione okręgi (`total_circles` nie jest puste), konwertuje
    obraz do przestrzeni kolorów BGR i przypisuje go do zmiennej `cimg`.

    Wywołuje funkcję `filtered_circles` w celu filtrowania kręgów w `total_circles`.
    """
    cimg = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)
    filtered = filtered_circles(total_circles)
    """
    Zwraca średni okrąg obliczony na podstawie przefiltrowanych okręgów, wywołując funkcję `get_mean_circle`.
    """
    return get_mean_circle(filtered)

def point_in_circle(c_col, c_row, c_radius, p_col, p_row):
    return distance(c_col, c_row, p_col, p_row) <= c_radius

"""
Definiuje wewnętrzną funkcję o nazwie `get_alpha_radius`, która oblicza i zwraca promień okręgu o najmniejszej całkowitej różnicy od promieni pozostałych okręgów. To koło nazwane jest „alfa”.

Odfiltrowania okręgów na podstawie ich pozycji i promieni:
Oblicza średnią i odchylenie standardowe współrzędnych x i współrzędnych y okręgów.

Inicjuje puste listy do przechowywania filtrowanych kręgów (`filtered`) i kręgów, które nie przeszły kryteriów filtrowania (`not_filtered`).

Stosuje filtrowanie w oparciu o pozycję: jeśli współrzędna x lub współrzędna y
okręgu wykracza poza zakres określony przez średnią ± `stosunek` pomnożony przez odchylenie standardowe,
jest uważany za niefiltrowany i dodawany do listy `not_filtered`. W przeciwnym razie jest
uważana za przefiltrowaną i dodaną do listy `filtered_pos`.

Jeśli liczba okręgów na liście `filtrowane_pozycje` jest mniejsza niż 3, przypisuje liście `filtrowanej`
równą liście `filtrowane_pozycje`.

Jeśli liczba okręgów na liście `filtered_pos` wynosi 3 lub więcej, oblicza promień alfa za pomocą funkcji 'get_alpha_radius`.Oblicza również średnią i odchylenie standardowe promieni okręgów na liście 'filtered_pos'.

Stosuje filtrowanie na podstawie promienia: jeśli promień okręgu wykracza poza zakres określony przez promień alfa ± odchylenie standardowe, jest uważany za niefiltrowany i dodawany do listy
`not_filtered`. W przeciwnym razie jest uważany za przefiltrowany i dodany do listy `filtered`.

Tworzy kopię obrazu `draw`.

Rysuje okręgi z listy `not_filtered` w kolorze niebieskim, z zewnętrznym okręgiem i punktem środkowym.

Rysuje okręgi z listy „filtrowanej” kolorem zielonym, z zewnętrznym okręgiem i punktem środkowym

Jeśli podany jest parametr `draw`, rysuje okręgi na obrazie draw`

Wyświetla obraz

Zwraca „przefiltrowaną” listę kręgów."""

def filtered_circles(circles, draw=None):

    def get_alpha_radius(circles0):
        alpha_circle = None
        dist_min = None
        circles1 = circles0[:]
        circles2 = circles0[:]
        for crt_c in circles1:
            dist = 0
            for c in circles2:
                dist += math.fabs(float(crt_c[2]) - float(c[2]))
            if not dist_min or dist < dist_min:
                dist_min = dist
                alpha_circle = crt_c
        return alpha_circle[2]



    if not circles:
        print ('Error: empty circles list in filtered_circles() !')
        return []

    c_0_mean, c_0_dev = standard_dev([int(i[0]) for i in circles])
    c_1_mean, c_1_dev = standard_dev([int(i[1]) for i in circles])

    filtered = []
    filtered_pos = []
    not_filtered = []
    ratio = 1.5

    for c in circles[:]:
        if c[0] < c_0_mean - ratio*c_0_dev or \
           c[0] > c_0_mean + ratio*c_0_dev or \
           c[1] < c_1_mean - ratio*c_1_dev or \
           c[1] > c_1_mean + ratio*c_1_dev:
            not_filtered.append(c)
        else:
            filtered_pos.append(c)

    if len([float(c[2]) for c in filtered_pos]) < 3:
        filtered = filtered_pos

    else:
        alpha_radius = get_alpha_radius(filtered_pos)
        mean_radius, dev_radius = standard_dev([float(c[2]) for c in filtered_pos])
        max_radius = alpha_radius + dev_radius
        min_radius = alpha_radius - dev_radius

        for c in filtered_pos:
            if c[2] < min_radius or \
               c[2] > max_radius:
                not_filtered.append(c)
            else:
                filtered.append(c)


    if draw is not None:
        """"""
        draw = draw.copy()
        for circle in not_filtered:

            cv2.circle(draw,(circle[0],circle[1]),circle[2],(255,0,0),1)
            cv2.circle(draw,(circle[0],circle[1]),2,(255,0,0),2)

        for circle in filtered:
            # draw the outer circle
            cv2.circle(draw,(circle[0],circle[1]),circle[2],(0,255,0),1)
            # draw the center of the circle
            cv2.circle(draw,(circle[0],circle[1]),2,(0,255,0),2)
        window_name = 'filtered_circles() total={0} filtered_pos={1} filtered={2}'.\
                   format(len(circles), len(filtered_pos), len(filtered))

        cv2.imshow(window_name, draw)
        ch = cv2.waitKey(0)
        cv2.destroyAllWindows()

    return filtered

"""Rysuje zewnętrzne koło źrenicy za pomocą `cv2.circle`. Środek okręgu jest określony przez `(pupil_circle[0], pupil_circle[1])`,
a promień jest określony przez `pupil_circle[2]`. Kolor okręgu to `(0,0,255)` (czerwony), a grubość jest ustawiona na 1.

Rysuje mały okrąg w środku okręgu źrenicy za pomocą `cv2.circle`. To koło reprezentuje środek źrenicy. Współrzędne środka
są takie same jak zewnętrzne koło źrenicy, a promień jest ustawiony na 1. Kolor jest również ustawiony na `(0,0,255)` (czerwony), a grubość wynosi 1.

Jeśli podano parametr `center_range`, rysuje on okrąg reprezentujący granicę zasięgu dla środka zewnętrznej tęczówki. Środek okręgu jest taki sam jak środek okręgu źrenicy,
a promień jest określony przez `center_range`. Kolor jest ustawiony na `(0,255,255)` (żółty), a grubość to 1.

Jeśli podano parametr `radius_range`, rysuje on okrąg reprezentujący granicę zasięgu dla promienia
 zewnętrznej tęczówki. Środek okręgu jest taki sam jak środek okręgu źrenicy, a promień jest
 określony przez `radius_range`. Kolor jest ustawiony na `(0,255,255)` (żółty), a grubość to 1.

 Rysuje zewnętrzny okrąg zewnętrznej tęczówki za pomocą `cv2.circle`. Środek okręgu jest
określony przez `(ext_iris_circle[0], ext_iris_circle[1])`, a promień jest określony przez
`ext_iris_circle[2]`. Kolor okręgu to `(0,255,0)` (zielony), a grubość jest ustawiona na 1.

Rysuje małe kółko w środku zewnętrznego okręgu tęczówki za pomocą `cv2.circle`.
 To koło reprezentuje środek zewnętrznej tęczówki. Współrzędne środka są takie same,
 jak zewnętrzny okrąg tęczówki zewnętrznej, a promień jest ustawiony na 1. Kolor jest
 również ustawiony na `(0,255,0)` (zielony), a grubość wynosi 1.
"""

def draw_circles(cimg, pupil_circle, ext_iris_circle,
                 center_range=None, radius_range=None):

    cv2.circle(cimg,(pupil_circle[0], pupil_circle[1]), pupil_circle[2],
                     (0,0,255),1)

    cv2.circle(cimg,(pupil_circle[0],pupil_circle[1]),1,(0,0,255),1)
    if center_range:

        cv2.circle(cimg,(pupil_circle[0], pupil_circle[1]), center_range,
                         (0,255,255),1)
    if radius_range:

        cv2.circle(cimg,(pupil_circle[0], pupil_circle[1]), radius_range,
                         (0,255,255),1)
    cv2.circle(cimg, (ext_iris_circle[0], ext_iris_circle[1]),
               ext_iris_circle[2],(0,255,0),1)

    cv2.circle(cimg, (ext_iris_circle[0], ext_iris_circle[1]),
               1,(0,255,0),1)

"""Definiuje wewnętrzną funkcję o nazwie `find_roi`, która tworzy maskę binarną na podstawie
danych wejściowych `img`, `ext_iris_circle` i `pupil_circle`. Maskę tworzy się rysując
białe kółka przedstawiające tęczówkę i źrenicę na czarnym obrazie.

Funkcja `find_roi` jest wywoływana w celu uzyskania obszaru
zainteresowania (ROI) poprzez nałożenie maski na dane wejściowe `img`.

Dla każdego piksela oblicza kąt (`theta`) między środkiem okręgu `ext_iris_circle` a danym pikselem.
Jeśli `theta` wynosi od 50 do 130 stopni, ustawia wartość piksela na zero, skutecznie maskując górną część tęczówki

Stosuje operację progowania (`cv2.threshold`) do ROI, ustawiając
wartości pikseli poniżej 50 na zero i wartości pikseli powyżej lub równe 50 na ich oryginalne wartości.

Funkcja `cv2.equalizeHist` jest wywoływana w celu wykonania
 wyrównania histogramu na `roi`, zapisując wynik w `equ_roi`.

 Łączy oryginalny ROI (`roi`) i wyrównany ROI (`equ_roi`) przy użyciu `
 cv2.addWeighted`, nadając większą wagę wyrównanemu ROI. Zwiększa to kontrast obszaru tęczówki.

 Jeśli parametr `show` jest ustawiony na `True`, wyświetla wyrównany obszar tęczówki
"""

def get_equalized_iris(img, ext_iris_circle, pupil_circle, show=False):

    def find_roi():
        mask = img.copy()
        mask[:] = (0)

        cv2.circle(mask,
                   (ext_iris_circle[0], ext_iris_circle[1]),
                   ext_iris_circle[2], (255), -1)
        cv2.circle(mask,
                   (pupil_circle[0],pupil_circle[1]),
                   pupil_circle[2],(0), -1)

        roi = cv2.bitwise_and(img, mask)

        return roi

    roi = find_roi()

    for p_col in range(roi.shape[1]):
        for p_row in range(roi.shape[0]):
            theta = angle_v(ext_iris_circle[0], ext_iris_circle[1],
                            p_col, p_row)
            if theta > 50 and theta < 130:
                roi[p_row,p_col] = 0

    ret, roi = cv2.threshold(roi,50,255,cv2.THRESH_TOZERO)

    equ_roi = roi.copy()
    cv2.equalizeHist(roi, equ_roi)
    roi = cv2.addWeighted(roi, 0.0, equ_roi, 1.0, 0)

    if show:
        window_name = 'equalized histogram iris region'
        cv2.imshow(window_name, roi)
        ch = cv2.waitKey(0)
        cv2.destroyAllWindows()

    return roi

"""Tworzy kopię obrazu wejściowego (`img`) i przypisuje ją do zmiennej `bg`.
 Obraz jest następnie wypełniany zerami przy użyciu `bg[:] = 0`.

 Inicjuje słowniki `init_dict` i 'rois'

 Dla każdego piksela sprawdza, czy piksel znajduje się poza okręgiem źrenicy i
wewnątrz okręgu zewnętrznego. Jeśli warunki są spełnione, przypisuje wartość
piksela z obrazu wejściowego do odpowiedniego obszaru zainteresowania (słownik `rois`)
na podstawie kąta (`theta`) obliczonego między zewnętrznym środkiem okręgu a bieżącym pikselem.

Jeśli `theta` wynosi od -50 do 50, wartość piksela jest przypisywana do obszaru ``prawej strony'`.
Jeśli `theta` jest większe lub równe 130 lub mniejsze lub równe -130, wartość piksela jest przypisywana do obszaru ``lewej strony'`.
Jeśli `theta` mieści się w przedziale od -140 do -40, wartość piksela jest przypisywana do regionu ``bottom'`.

Następnie kod modyfikuje współrzędne `ext_circle` dla każdego obszaru zainteresowania
(`'right-side'`, `'left-side'`, `'bottom'`, `'complete'`) na podstawie translacji ( `tx` i `ty`)
obliczone na podstawie oryginalnego `ext_circle`.

Stosuje transformację afiniczną (`cv2.warpAffine`) do
każdego interesującego obszaru obrazu (`rois[pos]['img']`) używając obliczonych wartości translacji.

Przycina obrazy każdego obszaru zainteresowania
(„prawa strona”, „lewa strona”, „dół”, „kompletny”) na podstawie ich odpowiednich rozmiarów.

Jeśli parametr `show` jest ustawiony na `True`, wyświetla obrazy każdego interesującego regionu



"""

def get_rois(img, pupil_circle, ext_circle, show=False):

    bg = img.copy()
    bg[:] = 0

    init_dict = {'img': bg.copy(),
                 'pupil_circle': pupil_circle,
                 'ext_circle': ext_circle,
                 'kp': None,
                 'img_kp_init': bg.copy(),
                 'img_kp_filtered': bg.copy(),
                 'des': None
                 }

    rois = {'right-side': copy.deepcopy(init_dict),
            'left-side': copy.deepcopy(init_dict),
            'bottom': copy.deepcopy(init_dict),
            'complete': copy.deepcopy(init_dict)
            }

    for p_col in range(img.shape[1]):
        for p_row in range(img.shape[0]):
            if not point_in_circle(pupil_circle[0], pupil_circle[1],
                                   pupil_circle[2], p_col, p_row) and \
               point_in_circle(ext_circle[0], ext_circle[1], ext_circle[2],
                                   p_col, p_row):
                theta = angle_v(ext_circle[0], ext_circle[1], p_col, p_row)
                if theta >= -50 and theta <= 50:
                    rois['right-side']['img'][p_row,p_col] = img[p_row,p_col]
                if theta >= 130 or theta <= -130:
                    rois['left-side']['img'][p_row,p_col] = img[p_row,p_col]
                if theta >= -140 and theta <= -40:
                    rois['bottom']['img'][p_row,p_col] = img[p_row,p_col]
                rois['complete']['img'][p_row,p_col] = img[p_row,p_col]

    ext_25 = int(2.5*ext_circle[2])
    ext_125 =int(1.25*ext_circle[2])


    rois['right-side']['ext_circle'] = \
            (0, ext_125, int(ext_circle[2]))
    rois['left-side']['ext_circle'] = \
            (ext_125,
             ext_125,
             int(ext_circle[2]))
    rois['bottom']['ext_circle'] = \
            (ext_125, 0, ext_125)
    rois['complete']['ext_circle'] = \
            (ext_125,
             ext_125,
             int(ext_circle[2]))

    for pos in ['right-side','left-side','bottom','complete']:
        tx = rois[pos]['ext_circle'][0] - ext_circle[0]
        ty = rois[pos]['ext_circle'][1] - ext_circle[1]
        rois[pos]['pupil_circle'] = (int(tx + pupil_circle[0]),
                                     int(ty + pupil_circle[1]),
                                     int(pupil_circle[2]))
        M = np.float32([[1,0,tx],[0,1,ty]])
        rois[pos]['img'] = cv2.warpAffine(
                            rois[pos]['img'], M,
                            (img.shape[1], img.shape[0]))


    rois['right-side']['img'] = \
        rois['right-side']['img'][0:ext_25, 0:ext_125]
    rois['left-side']['img'] = \
        rois['left-side']['img'][0:ext_25, 0:ext_125]
    rois['bottom']['img'] = \
        rois['bottom']['img'][0:ext_125, 0:ext_25]
    rois['complete']['img'] = \
        rois['complete']['img'][0:ext_25, 0:ext_25]

    if show:
        plt.subplot(2,2,1),plt.imshow(rois['right-side']['img'], cmap='gray')
        plt.title('right-side'),plt.xticks([]),plt.yticks([])
        plt.subplot(2,2,2),plt.imshow(rois['left-side']['img'], cmap='gray')
        plt.title('left-side'),plt.xticks([]),plt.yticks([])
        plt.subplot(2,2,3),plt.imshow(rois['bottom']['img'], cmap='gray')
        plt.title('bottom'),plt.xticks([]),plt.yticks([])
        plt.subplot(2,2,4),plt.imshow(rois['complete']['img'], cmap='gray')
        plt.title('complete'),plt.xticks([]),plt.yticks([])
        plt.show()

    return rois

"""Inicjuje obiekt Brute-Force Matcher za pomocą `cv2.BFMatcher()`

Dla każdej pozycji na liście `['prawa strona', 'lewa strona', 'dół', 'kompletna']' używa detektora funkcji
 SIFT (`sift`) do wykrywania punktów kluczowych na obrazie
`rois[pos]['img']` i przypisuje wykryte punkty kluczowe do `rois[pos]['kp'] `.

Następnie  wykonuje  operacje, aby zwizualizować punkty kluczowe:
Tworzy obraz z niefiltrowanymi punktami kluczowymi (`rois[pos]['img_kp_init']`)
za pomocą `cv2.drawKeypoints()`.

 Kluczowe punkty są rysowane kolorem zielonym.Rysuje okręgi
 wokół źrenicy i okręgu zewnętrznego na obrazie `rois[pos]['img_kp_init']` za pomocą `cv2.circle()`.

 Filtruje wykryte punkty kluczowe na podstawie  warunków:
Jeśli punkt kluczowy znajduje się wewnątrz okręgu źrenicy, jest usuwany
z listy punktów kluczowych (`rois[pos]['kp']`), a liczba jest zwiększana dla `wewnątrz`.

Jeśli punkt kluczowy znajduje się poza zewnętrznym okręgiem,
jest usuwany z listy punktów kluczowych, a liczba jest zwiększana dla `na zewnątrz`.

Jeśli punkt kluczowy ma kąt, który nie spełnia określonych warunków ,
jest usuwany z listy punktów kluczowych, a liczba jest zwiększana dla `wrong_angle`.

Tworzy obraz z filtrowanymi punktami kluczowymi (`rois[pos]['img_kp_filtered']`)
za pomocą `cv2.drawKeypoints()`. Filtrowane punkty kluczowe są rysowane kolorem zielonym.

Rysuje okręgi wokół źrenicy i zewnętrzny okrąg na obrazie `rois[pos]['img_kp_filtered']` za pomocą `cv2.circle()`.

Jeśli parametr `show` jest ustawiony na `True`, wyświetla obrazy z punktami kluczowymi
"""

def load_keypoints(sift, rois, show=False):

    bf = cv2.BFMatcher()

    for pos in ['right-side','left-side','bottom','complete']:
        rois[pos]['kp'] = sift.detect(rois[pos]['img'],None)

        rois[pos]['img_kp_init'] = cv2.drawKeypoints(
                                        rois[pos]['img'], rois[pos]['kp'],
                                        color=(0,255,0), flags=0,
                                        outImage=None)

        cv2.circle(
            rois[pos]['img_kp_init'],
            (rois[pos]['pupil_circle'][0], rois[pos]['pupil_circle'][1]),
            rois[pos]['pupil_circle'][2], (0,0,255), 1)
        cv2.circle(
            rois[pos]['img_kp_init'],
            (rois[pos]['ext_circle'][0], rois[pos]['ext_circle'][1]),
            rois[pos]['ext_circle'][2], (0,255,255), 1)

        inside = 0
        outside = 0
        wrong_angle = 0
        for kp in rois[pos]['kp'][:]:
            c_angle = angle_v(rois[pos]['ext_circle'][0],
                              rois[pos]['ext_circle'][1],
                              kp.pt[0], kp.pt[1])
            if point_in_circle(rois[pos]['pupil_circle'][0],
                               rois[pos]['pupil_circle'][1],
                               rois[pos]['pupil_circle'][2]+3,
                               kp.pt[0], kp.pt[1]):
                list(rois[pos]['kp']).remove(kp)
                inside +=1
            elif not point_in_circle(rois[pos]['ext_circle'][0],
                                     rois[pos]['ext_circle'][1],
                                     rois[pos]['ext_circle'][2]-5,
                                     kp.pt[0], kp.pt[1]):
                list(rois[pos]['kp']).remove(kp)
                outside +=1
            elif (pos == 'right-side' and (c_angle <= -45 or c_angle >= 45)) or \
                 (pos == 'left-side' and (c_angle <= 135 and c_angle >= -135)) or \
                 (pos == 'bottom' and (c_angle <= -135 or c_angle >= -45)):
                list(rois[pos]['kp']).remove(kp)
                wrong_angle +=1

        rois[pos]['img_kp_filtered'] = cv2.drawKeypoints(
                                rois[pos]['img'],rois[pos]['kp'],
                                color=(0,255,0), flags=0,
                                outImage=None)

        cv2.circle(
            rois[pos]['img_kp_filtered'],
            (rois[pos]['pupil_circle'][0],rois[pos]['pupil_circle'][1]),
            rois[pos]['pupil_circle'][2], (0,0,255), 1)
        cv2.circle(
            rois[pos]['img_kp_filtered'],
            (rois[pos]['ext_circle'][0],rois[pos]['ext_circle'][1]),
            rois[pos]['ext_circle'][2], (0,255,255), 1)

    if show:
        i=0
        for pos in ['right-side','left-side','bottom']:
            plt.subplot(3, 2, 2*i+1), \
            plt.imshow(rois[pos]['img_kp_init'])
            plt.xticks([]), plt.yticks([])
            plt.subplot(3, 2, 2*i+2), \
            plt.imshow(rois[pos]['img_kp_filtered'])
            plt.xticks([]), plt.yticks([])
            i+=1
        plt.show()

def load_descriptors(sift, rois):
    for pos in ['right-side','left-side','bottom','complete']:
        rois[pos]['kp'], rois[pos]['des'] = \
            sift.compute( rois[pos]['img'], rois[pos]['kp'] )

"""Inicjuje pustą listę `img_matches` do przechowywania
 dopasowanych obrazów oraz słownik `numberof_matches` do śledzenia liczby dopasowań dla różnych pozycji.

 Dla każdej pozycji sprawdza, czy `rois_1` lub `rois_2` nie ma zdefiniowanych
 punktów kluczowych (`kp`) dla tej pozycji. Jeśli tak, wypisze komunikat ,
 że punkty kluczowe nie zostały znalezione w jednym ze słowników .

  Jeśli zostaną znalezione punkty kluczowe zarówno dla `rois_1`, jak i `rois_2`
   w pozycji (`pos`), wywołuje funkcję `get_matches` z odpowiednimi słownikami
   `rois_1[pos]` i `rois_2[pos]`, wraz z innymi parametrami (`dratio`, `stdev_angle`, `stdev_dist`).

   Zwrócone dopasowania z `get_matches` są przechowywane w zmiennej `matches`,
a liczba dopasowań jest aktualizowana w słowniku `numberof_matches` dla  pozycji (`pos`).

jeśli parametr `show` jest ustawiony na `True`, wyswietla obraz z dopasowaniami.

Po iteracji przez wszystkie pozycje funkcja zwraca słownik
 `numberof_matches`, który zawiera liczbę dopasowań dla każdej pozycji.
"""

def getall_matches(rois_1, rois_2, dratio,
                   stdev_angle, stdev_dist, show=False):

    img_matches = []
    numberof_matches = {'right-side': 0,
                  'left-side': 0,
                  'bottom': 0,
                  'complete': 0}

    for pos in ['right-side','left-side','bottom','complete']:
        if not rois_1[pos]['kp'] or not rois_2[pos]['kp']:
            print ("KeyPoints not found in one of rois_x[pos]['kp'] !!!")
            print (" -->", pos, len(rois_1[pos]['kp']), len(rois_2[pos]['kp']))
        else:
            matches = get_matches(rois_1[pos], rois_2[pos],
                                   dratio, stdev_angle, stdev_dist)
            numberof_matches[pos] = len(matches)

        if show:
            print ("{0} matches: {1}".format(pos, str(len(matches))))
            crt_image = cv2.drawMatchesKnn(
                            rois_1[pos]['img'],rois_1[pos]['kp'],
                            rois_2[pos]['img'],rois_2[pos]['kp'],
                            [matches], flags=2, outImg=None)

            img_matches.append(crt_image)
            window_name = 'matches'
            cv2.imshow(window_name,  crt_image)
            ch = cv2.waitKey(0)
            cv2.destroyAllWindows()

    return numberof_matches

"""Sprawdza, czy `roipos_1` lub `roipos_2` nie ma zdefiniowanych 'kp'
 (punktów kluczowych). Jeśli tak, wypisuje komunikat, że nie
  znaleziono punktów kluczowych i zwraca pustą listę.

   Jeśli zostaną znalezione punkty kluczowe, inicjalizuje funkcję
  Brute-Force Matcher (`bf`)`.

  Następnie używa narzędzia dopasowującego, aby znaleźć k-najbliższych sąsiadów (`k=2`)
 dla każdego deskryptora (`roipos_1['des']` i `roipos_2['des']`) i przechowuje dopasowania w `matches.
 Punkty kluczowe są przechowywane w  `kp1` i `kp2`.

 Oblicza różnicę odległości między zewnętrznym okręgiem
a źrenicą dla obu `roipos_1` i `roipos_2`, zapisując je odpowiednio w zmiennych `diff_dist_1` i `diff_dist_2`.

Inicjuje puste listy `diff_angles`, `diff_dists` i `filtered`,
aby przechowywać odpowiednio obliczone różnice, odległości i filtrowane dopasowania.

Dla każdego dopasowanie w `matches wykonywane są operacje:

Sprawdza, czy stosunek odległości między najlepszym dopasowaniem (`m.distance`)
a drugim najlepszym dopasowaniem (`n.distance`) jest większy niż podany próg `dratio`. Jeśli tak, iteracja jest pomijana.

Pobiera współrzędne (x, y) dopasowanych punktów kluczowych z `kp1` i `kp2`.

Oblicza kąt między dopasowanym punktem kluczowym
a środkiem okręgu źrenicy zarówno dla `roipos_1`, jak i `roipos_2`, zapisując je jako `angle_1` i `angle_2`.

Oblicza różnicę kątów (`diff_angle`) i dołącza ją do listy `diff_angles`.

Oblicza znormalizowaną różnicę odległości dla dopasowanych punktów kluczowych, odejmując promień okręgu źrenicy
 od obliczonej odległości i dzieląc ją przez wcześniej obliczoną różnicę odległości (`diff_dist_1` i `diff_dist_2`).

 Oblicza różnicę odległości (`diff_dist`) i dołącza ją do listy `diff_dists`.

 Dodaje dopasowanie (`m`) do listy `filtrowanych`.

 Oblicza medianę listy `diff_angles` i przechowuje ją w `median_diff_angle`.
Oblicza medianę listy `diff_dists` i przechowuje ją w `median_diff_dist`.

Iteruje przez każde dopasowanie na liście „filtrowanych” i wykonuje następujące kontrole:

Pobiera współrzędne (x, y) dopasowanych punktów kluczowych z `kp1` i `kp2`.

Oblicza kąt między dopasowanym punktem kluczowym a środkiem okręgu źrenicy
zarówno dla `roipos_1`, jak i `roipos_2`, zapisując je jako `angle_1` i `angle_2`

Sprawdza, czy różnica kątów (`diff_angle`) mieści się w zakresie
`median_diff_angle - stdev_angle` i `median_diff_angle + stdev_angle`.

oblicza znormalizowaną różnicę odległości dla dopasowanych punktów kluczowych i
sprawdza, czy mieści się ona w zakresie `median_diff_dist - stdev_dist` i `median_diff_dist + stdev_dist`.

Jeśli zarówno kontrola kąta, jak i odległości wypadnie pomyślnie, iteracja
 zostaje zachowany; w przeciwnym razie jest usuwany z listy „filtrowanych”.

 Na koniec funkcja zwraca „przefiltrowaną” listę dopasowań.
"""

def get_matches(roipos_1, roipos_2,
                dratio, stdev_angle, stdev_dist):

    if not roipos_1['kp'] or not roipos_2['kp']:
        print ("KeyPoints not found in one of roipos_x['kp'] !!!")
        return []

    bf = cv2.BFMatcher()

    matches = bf.knnMatch(roipos_1['des'], roipos_2['des'], k=2)
    kp1 = roipos_1['kp']
    kp2 = roipos_2['kp']

    diff_dist_1 = roipos_1['ext_circle'][2] - roipos_1['pupil_circle'][2]
    diff_dist_2 = roipos_2['ext_circle'][2] - roipos_2['pupil_circle'][2]

    diff_angles = []
    diff_dists = []
    filtered = []

    for m,n in matches:


        if (m.distance/n.distance) > dratio:
            continue

        x1,y1 = kp1[m.queryIdx].pt
        x2,y2 = kp2[m.trainIdx].pt

        angle_1 = angle_v(
                x1,y1,
                roipos_1['pupil_circle'][0],
                roipos_1['pupil_circle'][1])
        angle_2 = angle_v(
                x2,y2,
                roipos_2['pupil_circle'][0],
                roipos_2['pupil_circle'][1])

        diff_angle = angle_1 - angle_2
        diff_angles.append(diff_angle)

        dist_1 = distance(x1,y1,
                          roipos_1['pupil_circle'][0],
                          roipos_1['pupil_circle'][1])
        dist_1 = dist_1 - roipos_1['pupil_circle'][2]
        dist_1 = dist_1 / diff_dist_1

        dist_2 = distance(x2,y2,
                          roipos_2['pupil_circle'][0],
                          roipos_2['pupil_circle'][1])
        dist_2 = dist_2 - roipos_2['pupil_circle'][2]
        dist_2 = dist_2 / diff_dist_2

        diff_dist = dist_1 - dist_2
        diff_dists.append(diff_dist)

        filtered.append(m)

    # Usuwanie złych dopasowań
    if True and filtered:

        median_diff_angle = median(diff_angles)
        median_diff_dist = median(diff_dists)
        #print( "median dist:", median_diff_dist)

        for m in filtered[:]:

            x1,y1 = kp1[m.queryIdx].pt
            x2,y2 = kp2[m.trainIdx].pt

            angle_1 = angle_v(
                x1,y1,
                roipos_1['pupil_circle'][0],
                roipos_1['pupil_circle'][1])
            angle_2 = angle_v(
                x2,y2,
                roipos_2['pupil_circle'][0],
                roipos_2['pupil_circle'][1])
            diff_angle = angle_1 - angle_2

            good_diff_angle = \
                (diff_angle > median_diff_angle - stdev_angle and \
                 diff_angle < median_diff_angle + stdev_angle)

            dist_1 = distance(x1,y1,
                              roipos_1['pupil_circle'][0],
                              roipos_1['pupil_circle'][1])
            dist_1 = dist_1 - roipos_1['pupil_circle'][2]
            dist_1 = dist_1 / diff_dist_1

            dist_2 = distance(x2,y2,
                              roipos_2['pupil_circle'][0],
                              roipos_2['pupil_circle'][1])
            dist_2 = dist_2 - roipos_2['pupil_circle'][2]
            dist_2 = dist_2 / diff_dist_2

            diff_dist = dist_1 - dist_2
            good_dist = (diff_dist > median_diff_dist - stdev_dist and \
                         diff_dist < median_diff_dist + stdev_dist)

            if good_diff_angle and good_dist:
                continue

            filtered.remove(m)

    return filtered

def angle_v(x1,y1,x2,y2):
    return math.degrees(math.atan2(-(y2-y1),(x2-x1)))

def distance(x1,y1,x2,y2):
    dst = math.sqrt((x2-x1)**2 + (y2-y1)**2)
    return dst

def mean(x):
    sum = 0.0
    for i in range(len(x)):
        sum += x[i]
    return sum/len(x)

def median(x):
    return np.median(np.array(x))

"""
odchylenie standardowe
"""
def standard_dev(x):
    if not x:
        print ('Error: empty list parameter in standard_dev() !')
        print (inspect.getouterframes( inspect.currentframe() )[1])
        print
        return None, None
    m = mean(x)
    sumsq = 0.0
    for i in range(len(x)):
        sumsq += (x[i] - m) ** 2
    return m, math.sqrt(sumsq/len(x))

# """"Wczytywanie ROIs z plików binarnych"""
# def load_rois_from_bin(bin_path):
#     with gzip.open(bin_path, 'rb') as bin_file:
#         rois = pickle.load(bin_file)
#     unpickle_rois(rois)
#     return rois

# """
# Podział ROIs na częsci prawą, lewą i dolną
# """
# def unpickle_rois(rois):
#     for pos in ['right-side','left-side','bottom','complete']:
#         rois[pos]['kp'] = unpickle_keypoints(rois[pos]['kp'])

# """
# odczyatnie punktów charakterystyczych
# """
# def unpickle_keypoints(array):
#     keypoints = []
#     for point in array:
#         temp_kp = cv2.KeyPoint(x=point[0][0],y=point[0][1],_size=point[1],
#                                _angle=point[2], _response=point[3],
#                                _octave=point[4], _class_id=point[5])
#         keypoints.append(temp_kp)
#     return keypoints

# def pickle_rois(rois):
#     for pos in ['right-side','left-side','bottom','complete']:
#         rois[pos]['kp'] = pickle_keypoints(rois[pos]['kp'])

# def pickle_keypoints(keypoints):
#     unfolded = []
#     for point in keypoints:
#         temp = (point.pt, point.size, point.angle, point.response,
#                 point.octave, point.class_id)
#         unfolded.append(temp)

#     return unfolded

"""Po wczytaniu listy scieżek do zdjęć images tworzona jest lista kombinacji z powtórzeniami zawierajaca pary scieżek.

Następnie porównuje zdjęcie 1 ze zdjęcięciem 1, zdjęcie 2 ze zdjęcięciem 2 oraz  zdjęcie 1 ze zdjęcięciem 2 i odczytuje liczbę dopasowań (numberOfMatches11, numberOfMatches22, numberOfMatches12) z funckji compare_images.

Oblicza próg dapasowania acceptance_threshold, który decyduje czy zdjęcia przedstawiają te same oczy. Próg jest równy 80% średniej liczby dopasowań numberOfMatches11, numberOfMatches22

na koniec sprawdza czy numberOfMatches12 jest powyżej progu dopasowania  acceptance_threshold
"""

if __name__ == "__main__":
  # images = [r'./S2001R01.jpg',r'./S2001R09.jpg',r'./S2002R01.jpg',
  #            r'./S2002R20.jpg',r'./S2005R07.jpg', r'./S2005R09.jpg']

    images = [r'./S2001R01.jpg',r'./S2001R09.jpg']
    # file_combinations = list(itertools.combinations_with_replacement(images, 2))
    file_combinations = list(itertools.combinations(images, 2))
    trues = 0
    falses = 0

    print(file_combinations)

    for comb in file_combinations:

      filepath1 = comb[0]
      filepath2 = comb[1]

      if os.path.isfile(filepath1) and os.path.isfile(filepath2):
        # matching image 1 with 1
        numberOfMatches11 = compare_images(filepath1, filepath1)
        print("Matches 1 - 1",numberOfMatches11)
        numberOfMatches11 = np.array(list(numberOfMatches11.values()))
        # print("Matches 1 - 1",numberOfMatches11)

        #matching image 2 with 2
        numberOfMatches22 = compare_images(filepath2, filepath2)
        print("Matches 2 - 2",numberOfMatches22)
        numberOfMatches22 = np.array(list(numberOfMatches22.values()))
        # print("Matches 2 - 2",numberOfMatches22)

        #matching image 1 with 2
        numberOfMatches12 = compare_images(filepath1, filepath2)
        print("Matches 1 - 2",numberOfMatches12)
        numberOfMatches12 = np.array(list(numberOfMatches12.values()))
        # print("Matches 1 - 2",numberOfMatches12)

        acceptance_threshold = (numberOfMatches11 + numberOfMatches22)/2 * 0.8
        print("acceptance_threshold " , acceptance_threshold)

        if(all(acceptance_threshold[0:3] <  numberOfMatches12[0:3])):
          print("Its the same eye")
          load_image(r"./true.png", show=True)
          trues += 1
        else:
          print("its different eyes")
          load_image(r"./false.png", show=True)
          falses += 1

      print("true ", trues, " false ", falses)